
# npods-support - supporting network and namespace for npods-workload
npods-workload: 
    type: metta.plugin.workload
    plugin_id: metta_kubernetes_helm

    # build the plugin from this config, by passing this label/base to it
    from_config: true

    namespace: npods
    chart: "{{paths:project}}/npods-helm"

    file: "{{variables:files_path}}/{{variables:resource_prefix}}.helm.npods.yaml"
    values:
      trigger:
        # start with 100 threads, we will manually run triggers so that we can scale the volume
        threads: 100
      workloads:
      # Heavier workload, starting at 100 pods
      - name: heavy
        image: msr.ci.mirantis.com/jnesbitt/n-pods-app:0.16
        replicas: 100
        sleep: 0s 
        cpu: 100
        ram: 8192
      # leander workload, starting at 100 pods
      - name: lean
        image: msr.ci.mirantis.com/jnesbitt/n-pods-app:0.16
        replicas: 100
        sleep: 1s 
        cpu: 0
        ram: 0


# loki workload : monitoring tooling workload
loki-workload:
    type: metta.plugin.workload
    plugin_id: metta_kubernetes_helm

    # build the plugin from this config, by passing this label/base to it
    from_config: true

    repos:
      grafana: https://grafana.github.io/helm-charts

    namespace: loki
    chart: grafana/loki-stack

    file: "{{variables:files_path}}/{{variables:resource_prefix}}.helm.loki.yaml"
    values:

      grafana:
        enabled: true

        adminUser: admin
        adminPassword: admin

        dashboardProviders:
          dashboardproviders.yaml:
            apiVersion: 1
            providers:
              - name: default
                orgId: 1
                folder: ""
                type: file
                disableDeletion: false
                editable: false
                options:
                  path: /var/lib/grafana/dashboards/default

        dashboards:
          default:
            node-exporter-server-metrics:
              folder: general
              gnetId: 405
              version: 8
              datasource: Prometheus

      prometheus:
        enabled: true
        alertmanager:
          persistentVolume:
            enabled: false
        server:
          persistentVolume:
            enabled: false
