
# npods-support - supporting network and namespace for npods-workload
npods-workload:
    type: metta.plugin.workload
    plugin_id: metta_kubernetes_helm

    # build the plugin from this config, by passing this label/base to it
    from_config: true

    namespace: npods
    chart: "{{paths:project}}/npods-app/helm"

    file: "{{variables:files_path}}/{{variables:resource_prefix}}.helm.npods.yaml"
    values:
      # start with a small number of workloads for sanity testing.
      workloads:
      - name: initial
        image: msr.ci.mirantis.com/jnesbitt/n-pods-app:0.18
        replicas: 1
        sleep: 100ms
        cpu: "10"
        ram: "128"
        threads: 1


# loki workload : monitoring tooling workload
loki-workload:
    type: metta.plugin.workload
    plugin_id: metta_kubernetes_helm

    # build the plugin from this config, by passing this label/base to it
    from_config: true

    repos:
      grafana: https://grafana.github.io/helm-charts

    namespace: loki
    chart: grafana/loki-stack

    file: "{{variables:files_path}}/{{variables:resource_prefix}}.helm.loki.yaml"
    values:

      grafana:
        enabled: true
        image:
          tag: 7.4.5

        adminUser: admin
        adminPassword: admin

        dashboardProviders:
          dashboardproviders.yaml:
            apiVersion: 1
            providers:
              - name: default
                orgId: 1
                folder: ""
                type: file
                disableDeletion: false
                editable: true
                options:
                  path: /var/lib/grafana/dashboards/default

        dashboards:
          default:
            node-exporter-server-metrics:
              folder: general
              gnetId: 11952
              version: 1
              datasource: Prometheus
              refresh: 10s
              time:
                from: "now-30m"
                to: "now"

      prometheus:
        enabled: true
        alertmanager:
          persistentVolume:
            enabled: false
        server:
          persistentVolume:
            enabled: false
